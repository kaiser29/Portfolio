{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac9abae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f626907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Pretest(Easy)</th>\n",
       "      <th>Posttest(Easy)</th>\n",
       "      <th>Easy Learning Gain</th>\n",
       "      <th>Easy Learning Gain (z)</th>\n",
       "      <th>Pretest(Average)</th>\n",
       "      <th>Posttest(Average)</th>\n",
       "      <th>Average Learning Gain</th>\n",
       "      <th>Average Learning Gain (z)</th>\n",
       "      <th>Pretest(Difficult)</th>\n",
       "      <th>Posttest(Difficult)</th>\n",
       "      <th>Difficult Learning Gain</th>\n",
       "      <th>Difficult Learning Gain (z)</th>\n",
       "      <th>Pretest(Total)</th>\n",
       "      <th>Posttest(Total)</th>\n",
       "      <th>Total Learning Gain</th>\n",
       "      <th>Total Learning Gain (z)</th>\n",
       "      <th>Mean difference</th>\n",
       "      <th>4.27027027</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.739295</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264526</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.187095</td>\n",
       "      <td>Standard Deviation</td>\n",
       "      <td>#MACRO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193334</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.843204</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.626048</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.796373</td>\n",
       "      <td>Standard error of the mean difference</td>\n",
       "      <td>#MACRO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.659648</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.399972</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.626048</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.796373</td>\n",
       "      <td>T-statistic</td>\n",
       "      <td>#MACRO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193334</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929723</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.349091</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.402986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272980</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.372954</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.349091</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.009599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Pretest(Easy)  Posttest(Easy)  Easy Learning Gain  \\\n",
       "0        5              7               9                   2   \n",
       "1        6             10              10                   0   \n",
       "2       14              9               8                  -1   \n",
       "3       15              8               8                   0   \n",
       "4       16              9              10                   1   \n",
       "\n",
       "   Easy Learning Gain (z)  Pretest(Average)  Posttest(Average)  \\\n",
       "0                0.739295                 5                  7   \n",
       "1               -0.193334                 7                  7   \n",
       "2               -0.659648                 8                  9   \n",
       "3               -0.193334                 5                  9   \n",
       "4                0.272980                 5                 10   \n",
       "\n",
       "   Average Learning Gain  Average Learning Gain (z)  Pretest(Difficult)  \\\n",
       "0                      2                   0.043259                   9   \n",
       "1                      0                  -0.843204                   4   \n",
       "2                      1                  -0.399972                   9   \n",
       "3                      4                   0.929723                   8   \n",
       "4                      5                   1.372954                   8   \n",
       "\n",
       "   Posttest(Difficult)  Difficult Learning Gain  Difficult Learning Gain (z)  \\\n",
       "0                   10                        1                    -0.264526   \n",
       "1                    4                        0                    -0.626048   \n",
       "2                    9                        0                    -0.626048   \n",
       "3                    6                       -2                    -1.349091   \n",
       "4                    6                       -2                    -1.349091   \n",
       "\n",
       "   Pretest(Total)  Posttest(Total)  Total Learning Gain  \\\n",
       "0              21               26                    5   \n",
       "1              21               21                    0   \n",
       "2              26               26                    0   \n",
       "3              21               23                    2   \n",
       "4              22               26                    4   \n",
       "\n",
       "   Total Learning Gain (z)                        Mean difference 4.27027027  \n",
       "0                 0.187095                     Standard Deviation    #MACRO?  \n",
       "1                -0.796373  Standard error of the mean difference    #MACRO?  \n",
       "2                -0.796373                            T-statistic    #MACRO?  \n",
       "3                -0.402986                                    NaN        NaN  \n",
       "4                -0.009599                                    NaN        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./DGBL Learning Gain DataSet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71d5e243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Pretest(Easy)</th>\n",
       "      <th>Posttest(Easy)</th>\n",
       "      <th>Easy Learning Gain</th>\n",
       "      <th>Easy Learning Gain (z)</th>\n",
       "      <th>Pretest(Average)</th>\n",
       "      <th>Posttest(Average)</th>\n",
       "      <th>Average Learning Gain</th>\n",
       "      <th>Average Learning Gain (z)</th>\n",
       "      <th>Pretest(Difficult)</th>\n",
       "      <th>Posttest(Difficult)</th>\n",
       "      <th>Difficult Learning Gain</th>\n",
       "      <th>Difficult Learning Gain (z)</th>\n",
       "      <th>Pretest(Total)</th>\n",
       "      <th>Posttest(Total)</th>\n",
       "      <th>Total Learning Gain</th>\n",
       "      <th>Total Learning Gain (z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.739295</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264526</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.187095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193334</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.843204</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.626048</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.796373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.659648</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.399972</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.626048</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.796373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193334</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929723</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.349091</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.402986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272980</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.372954</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.349091</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.009599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID  Pretest(Easy)  Posttest(Easy)  Easy Learning Gain  \\\n",
       "0        5              7               9                   2   \n",
       "1        6             10              10                   0   \n",
       "2       14              9               8                  -1   \n",
       "3       15              8               8                   0   \n",
       "4       16              9              10                   1   \n",
       "\n",
       "   Easy Learning Gain (z)  Pretest(Average)  Posttest(Average)  \\\n",
       "0                0.739295                 5                  7   \n",
       "1               -0.193334                 7                  7   \n",
       "2               -0.659648                 8                  9   \n",
       "3               -0.193334                 5                  9   \n",
       "4                0.272980                 5                 10   \n",
       "\n",
       "   Average Learning Gain  Average Learning Gain (z)  Pretest(Difficult)  \\\n",
       "0                      2                   0.043259                   9   \n",
       "1                      0                  -0.843204                   4   \n",
       "2                      1                  -0.399972                   9   \n",
       "3                      4                   0.929723                   8   \n",
       "4                      5                   1.372954                   8   \n",
       "\n",
       "   Posttest(Difficult)  Difficult Learning Gain  Difficult Learning Gain (z)  \\\n",
       "0                   10                        1                    -0.264526   \n",
       "1                    4                        0                    -0.626048   \n",
       "2                    9                        0                    -0.626048   \n",
       "3                    6                       -2                    -1.349091   \n",
       "4                    6                       -2                    -1.349091   \n",
       "\n",
       "   Pretest(Total)  Posttest(Total)  Total Learning Gain  \\\n",
       "0              21               26                    5   \n",
       "1              21               21                    0   \n",
       "2              26               26                    0   \n",
       "3              21               23                    2   \n",
       "4              22               26                    4   \n",
       "\n",
       "   Total Learning Gain (z)  \n",
       "0                 0.187095  \n",
       "1                -0.796373  \n",
       "2                -0.796373  \n",
       "3                -0.402986  \n",
       "4                -0.009599  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0060e7",
   "metadata": {},
   "source": [
    "# Mean Difference of Pretest and Posttest (Easy, Average, Difficult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25150b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.864864864864865"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_easy = df['Pretest(Easy)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a6eaf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.513513513513514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_easy = df['Posttest(Easy)'].mean()\n",
    "post_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dce01e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.45945945945946\n",
      "7.45945945945946\n"
     ]
    }
   ],
   "source": [
    "pre_ave = df['Pretest(Average)'].mean()\n",
    "post_ave = df['Posttest(Average)'].mean()\n",
    "\n",
    "print(pre_ave)\n",
    "print(post_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a40d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.54054054054054\n",
      "7.162162162162162\n"
     ]
    }
   ],
   "source": [
    "pre_diff = df['Pretest(Difficult)'].mean()\n",
    "post_diff = df['Posttest(Difficult)'].mean()\n",
    "\n",
    "print(pre_diff)\n",
    "print(post_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9928127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Pretest(Easy)</th>\n",
       "      <th>Posttest(Easy)</th>\n",
       "      <th>Easy Learning Gain</th>\n",
       "      <th>Easy Learning Gain (z)</th>\n",
       "      <th>Pretest(Average)</th>\n",
       "      <th>Posttest(Average)</th>\n",
       "      <th>Average Learning Gain</th>\n",
       "      <th>Average Learning Gain (z)</th>\n",
       "      <th>Pretest(Difficult)</th>\n",
       "      <th>Posttest(Difficult)</th>\n",
       "      <th>Difficult Learning Gain</th>\n",
       "      <th>Difficult Learning Gain (z)</th>\n",
       "      <th>Pretest(Total)</th>\n",
       "      <th>Posttest(Total)</th>\n",
       "      <th>Total Learning Gain</th>\n",
       "      <th>Total Learning Gain (z)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.594595</td>\n",
       "      <td>7.864865</td>\n",
       "      <td>8.513514</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.109140</td>\n",
       "      <td>5.459459</td>\n",
       "      <td>7.459459</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>5.540541</td>\n",
       "      <td>7.162162</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>-0.039796</td>\n",
       "      <td>18.864865</td>\n",
       "      <td>23.135135</td>\n",
       "      <td>4.270270</td>\n",
       "      <td>0.043562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.674572</td>\n",
       "      <td>1.782043</td>\n",
       "      <td>1.865202</td>\n",
       "      <td>2.016821</td>\n",
       "      <td>0.940472</td>\n",
       "      <td>2.467507</td>\n",
       "      <td>1.591551</td>\n",
       "      <td>2.321398</td>\n",
       "      <td>1.028917</td>\n",
       "      <td>2.683226</td>\n",
       "      <td>2.048218</td>\n",
       "      <td>2.628385</td>\n",
       "      <td>0.950219</td>\n",
       "      <td>5.637977</td>\n",
       "      <td>3.945195</td>\n",
       "      <td>5.178206</td>\n",
       "      <td>1.018520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-1.592277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.729667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-2.072135</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-1.976535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.659648</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.843204</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.626048</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.599679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.193334</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.264526</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.009599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.739295</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.486491</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.458518</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.580482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.604551</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.145881</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.627650</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.334192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User ID  Pretest(Easy)  Posttest(Easy)  Easy Learning Gain  \\\n",
       "count  37.000000      37.000000       37.000000           37.000000   \n",
       "mean   39.594595       7.864865        8.513514            0.648649   \n",
       "std    15.674572       1.782043        1.865202            2.016821   \n",
       "min     5.000000       4.000000        5.000000           -3.000000   \n",
       "25%    31.000000       7.000000        7.000000           -1.000000   \n",
       "50%    42.000000       8.000000        8.000000            0.000000   \n",
       "75%    52.000000       9.000000       10.000000            2.000000   \n",
       "max    61.000000      10.000000       16.000000            6.000000   \n",
       "\n",
       "       Easy Learning Gain (z)  Pretest(Average)  Posttest(Average)  \\\n",
       "count               37.000000         37.000000          37.000000   \n",
       "mean                 0.109140          5.459459           7.459459   \n",
       "std                  0.940472          2.467507           1.591551   \n",
       "min                 -1.592277          0.000000           5.000000   \n",
       "25%                 -0.659648          4.000000           6.000000   \n",
       "50%                 -0.193334          6.000000           7.000000   \n",
       "75%                  0.739295          7.000000           9.000000   \n",
       "max                  2.604551          9.000000          10.000000   \n",
       "\n",
       "       Average Learning Gain  Average Learning Gain (z)  Pretest(Difficult)  \\\n",
       "count              37.000000                  37.000000           37.000000   \n",
       "mean                2.000000                   0.043259            5.540541   \n",
       "std                 2.321398                   1.028917            2.683226   \n",
       "min                -2.000000                  -1.729667            0.000000   \n",
       "25%                 0.000000                  -0.843204            4.000000   \n",
       "50%                 2.000000                   0.043259            6.000000   \n",
       "75%                 3.000000                   0.486491            8.000000   \n",
       "max                 9.000000                   3.145881            9.000000   \n",
       "\n",
       "       Posttest(Difficult)  Difficult Learning Gain  \\\n",
       "count            37.000000                37.000000   \n",
       "mean              7.162162                 1.621622   \n",
       "std               2.048218                 2.628385   \n",
       "min               3.000000                -4.000000   \n",
       "25%               6.000000                 0.000000   \n",
       "50%               7.000000                 1.000000   \n",
       "75%               9.000000                 3.000000   \n",
       "max              10.000000                 9.000000   \n",
       "\n",
       "       Difficult Learning Gain (z)  Pretest(Total)  Posttest(Total)  \\\n",
       "count                    37.000000       37.000000        37.000000   \n",
       "mean                     -0.039796       18.864865        23.135135   \n",
       "std                       0.950219        5.637977         3.945195   \n",
       "min                      -2.072135        5.000000        16.000000   \n",
       "25%                      -0.626048       16.000000        20.000000   \n",
       "50%                      -0.264526       21.000000        22.000000   \n",
       "75%                       0.458518       22.000000        26.000000   \n",
       "max                       2.627650       28.000000        30.000000   \n",
       "\n",
       "       Total Learning Gain  Total Learning Gain (z)  \n",
       "count            37.000000                37.000000  \n",
       "mean              4.270270                 0.043562  \n",
       "std               5.178206                 1.018520  \n",
       "min              -6.000000                -1.976535  \n",
       "25%               1.000000                -0.599679  \n",
       "50%               4.000000                -0.009599  \n",
       "75%               7.000000                 0.580482  \n",
       "max              21.000000                 3.334192  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66602e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 3\n",
    "ind = np.arange(N) \n",
    "width = 0.25\n",
    "\n",
    "#Pretest Mean(Easy, Average, Difficult)\n",
    "xvals = [7.864865,5.459459,5.540541\t]\n",
    "bar1 = plt.bar(ind, xvals, width, color = 'r')\n",
    "\n",
    "#Posttest Mean(Easy, Average, Difficult)\n",
    "yvals = [8.513514,7.459459, 7.162162]\n",
    "bar2 = plt.bar(ind+width, yvals, width, color='g')\n",
    "\n",
    "#Learning Gain Mean(Easy, Average, Difficult)\n",
    "zvals = [0.648649,2.000000,1.621622]\n",
    "bar3 = plt.bar(ind+width*2, zvals, width, color = 'b')\n",
    "  \n",
    "plt.xlabel(\"Dates\")\n",
    "plt.ylabel('Scores')\n",
    "plt.title(\"Players Score\")\n",
    "  \n",
    "\n",
    "plt.legend( (bar1, bar2, bar3), ('Easy Learning Gain', 'Average Learning Gain', 'Difficult Learning Gain') )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530dd345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
